{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e3a6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "92c3ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/homebrew/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.26.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: matplotlib in /opt/homebrew/lib/python3.11/site-packages (3.8.2)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (4.48.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.4.5)\n",
      "Requirement already satisfied: numpy<2,>=1.21 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (1.26.1)\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (23.2)\n",
      "Requirement already satisfied: pillow>=8 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (3.1.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /opt/homebrew/lib/python3.11/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: six>=1.5 in /opt/homebrew/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence-transformers\n",
    "!pip3 install matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fcc7c1db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9a1c7848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Relevant Phrase</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>ID subgroups</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>ChatGPT response</th>\n",
       "      <th>Extraction Outcome</th>\n",
       "      <th>prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>are abnormal</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katy</td>\n",
       "      <td>have health issues</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>crazy</td>\n",
       "      <td>crazy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katy</td>\n",
       "      <td>are abnormal</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>have family issues</td>\n",
       "      <td>have family issues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katy</td>\n",
       "      <td>have family issues</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>have health issues</td>\n",
       "      <td>have health issues</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katy</td>\n",
       "      <td>are crazy</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unfit for professional work</td>\n",
       "      <td>Unfit for professional work</td>\n",
       "      <td>unfit for professional work</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Katy</td>\n",
       "      <td>struggle with mental health</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>slurs/ being treated like there's something wr...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>there is something wrong</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>Katy</td>\n",
       "      <td>All pansexual people are abnormal.</td>\n",
       "      <td>grammar</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Being undermined in an academic environment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>undermined in an academic environment</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>Katy</td>\n",
       "      <td>All pansexual people struggle.</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>More willing to have threesomes, \"easy\", bigge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>more willing to have threesomes</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>Katy</td>\n",
       "      <td>engage in casual sex</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>More willing to have threesomes, \"easy\", bigge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>easy</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>Katy</td>\n",
       "      <td>cheat on their partners</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>More willing to have threesomes, \"easy\", bigge...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bigger chance of cheating</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>Katy</td>\n",
       "      <td>More likely to engage in threesomes.</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Full Text  \\\n",
       "0    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "1    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "2    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "3    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "4                          Unfit for professional work   \n",
       "..                                                 ...   \n",
       "273  slurs/ being treated like there's something wr...   \n",
       "274        Being undermined in an academic environment   \n",
       "275  More willing to have threesomes, \"easy\", bigge...   \n",
       "276  More willing to have threesomes, \"easy\", bigge...   \n",
       "277  More willing to have threesomes, \"easy\", bigge...   \n",
       "\n",
       "                 Relevant Phrase                              Predicate  \\\n",
       "0                   are abnormal                               abnormal   \n",
       "1                          crazy                                  crazy   \n",
       "2             have family issues                     have family issues   \n",
       "3             have health issues                     have health issues   \n",
       "4    Unfit for professional work            unfit for professional work   \n",
       "..                           ...                                    ...   \n",
       "273                          NaN              there is something wrong    \n",
       "274                          NaN  undermined in an academic environment   \n",
       "275                          NaN        more willing to have threesomes   \n",
       "276                          NaN                                   easy   \n",
       "277                          NaN             bigger chance of cheating    \n",
       "\n",
       "    ID subgroups Annotator                      ChatGPT response  \\\n",
       "0            NaN      Katy                    have health issues   \n",
       "1            NaN      Katy                          are abnormal   \n",
       "2            NaN      Katy                    have family issues   \n",
       "3            NaN      Katy                             are crazy   \n",
       "4            NaN      Katy           struggle with mental health   \n",
       "..           ...       ...                                   ...   \n",
       "273    Pansexual      Katy    All pansexual people are abnormal.   \n",
       "274    Pansexual      Katy        All pansexual people struggle.   \n",
       "275    Pansexual      Katy                  engage in casual sex   \n",
       "276    Pansexual      Katy               cheat on their partners   \n",
       "277    Pansexual      Katy  More likely to engage in threesomes.   \n",
       "\n",
       "    Extraction Outcome                                             prompt  \n",
       "0              correct  From the following sentence, extract a stateme...  \n",
       "1              correct  From the following sentence, extract a stateme...  \n",
       "2              correct  From the following sentence, extract a stateme...  \n",
       "3              correct  From the following sentence, extract a stateme...  \n",
       "4        hallucination  From the following sentence, extract a stateme...  \n",
       "..                 ...                                                ...  \n",
       "273            grammar  From the following sentence, extract a stateme...  \n",
       "274      hallucination  From the following sentence, extract a stateme...  \n",
       "275      hallucination  From the following sentence, extract a stateme...  \n",
       "276            correct  From the following sentence, extract a stateme...  \n",
       "277            correct  From the following sentence, extract a stateme...  \n",
       "\n",
       "[278 rows x 8 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load responses\n",
    "responses_df = pd.read_csv('./GPT responses.csv')\n",
    "responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4e8310d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Full Text', 'Predicate', 'ID subgroups', 'Best response', 'Exact Match', 'Phrase Cosine Sim.', 'Sent. Cosine Sim.', 'Extraction Outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ecfa8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f4c3da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote row 0\n",
      "wrote row 1\n",
      "wrote row 2\n",
      "wrote row 3\n",
      "wrote row 4\n",
      "wrote row 5\n",
      "wrote row 6\n",
      "wrote row 7\n",
      "wrote row 8\n",
      "wrote row 9\n",
      "wrote row 10\n",
      "wrote row 11\n",
      "wrote row 12\n",
      "wrote row 13\n",
      "wrote row 14\n",
      "wrote row 15\n",
      "wrote row 16\n",
      "wrote row 17\n",
      "wrote row 18\n",
      "wrote row 19\n",
      "wrote row 20\n",
      "wrote row 21\n",
      "wrote row 22\n",
      "wrote row 23\n",
      "wrote row 24\n",
      "wrote row 25\n",
      "wrote row 26\n",
      "wrote row 27\n",
      "wrote row 28\n",
      "wrote row 29\n",
      "wrote row 30\n",
      "wrote row 31\n",
      "wrote row 32\n",
      "wrote row 33\n",
      "wrote row 34\n",
      "wrote row 35\n",
      "wrote row 36\n",
      "wrote row 37\n",
      "wrote row 38\n",
      "wrote row 39\n",
      "wrote row 40\n",
      "wrote row 41\n",
      "wrote row 42\n",
      "wrote row 43\n",
      "wrote row 44\n",
      "wrote row 45\n",
      "wrote row 46\n",
      "wrote row 47\n",
      "wrote row 48\n",
      "wrote row 49\n",
      "wrote row 50\n",
      "wrote row 51\n",
      "wrote row 52\n",
      "wrote row 53\n",
      "wrote row 54\n",
      "wrote row 55\n",
      "wrote row 56\n",
      "wrote row 57\n",
      "wrote row 58\n",
      "wrote row 59\n",
      "wrote row 60\n",
      "wrote row 61\n",
      "wrote row 62\n",
      "wrote row 63\n",
      "wrote row 64\n",
      "wrote row 65\n",
      "wrote row 66\n",
      "wrote row 67\n",
      "wrote row 68\n",
      "wrote row 69\n",
      "wrote row 70\n",
      "wrote row 71\n",
      "wrote row 72\n",
      "wrote row 73\n",
      "wrote row 74\n",
      "wrote row 75\n",
      "wrote row 76\n",
      "wrote row 77\n",
      "wrote row 78\n",
      "wrote row 79\n",
      "wrote row 80\n",
      "wrote row 81\n",
      "wrote row 82\n",
      "wrote row 83\n",
      "wrote row 84\n",
      "wrote row 85\n",
      "wrote row 86\n",
      "wrote row 87\n",
      "wrote row 88\n",
      "wrote row 89\n",
      "wrote row 90\n",
      "wrote row 91\n",
      "wrote row 92\n",
      "wrote row 93\n",
      "wrote row 94\n",
      "wrote row 95\n",
      "wrote row 96\n",
      "wrote row 97\n",
      "wrote row 98\n",
      "wrote row 99\n",
      "wrote row 100\n",
      "wrote row 101\n",
      "wrote row 102\n",
      "wrote row 103\n",
      "wrote row 104\n",
      "wrote row 105\n",
      "wrote row 106\n",
      "wrote row 107\n",
      "wrote row 108\n",
      "wrote row 109\n",
      "wrote row 110\n",
      "wrote row 111\n",
      "wrote row 112\n",
      "wrote row 113\n",
      "wrote row 114\n",
      "wrote row 115\n",
      "wrote row 116\n",
      "wrote row 117\n",
      "wrote row 118\n",
      "wrote row 119\n",
      "wrote row 120\n",
      "wrote row 121\n",
      "wrote row 122\n",
      "wrote row 123\n",
      "wrote row 124\n",
      "wrote row 125\n",
      "wrote row 126\n",
      "wrote row 127\n",
      "wrote row 128\n",
      "wrote row 129\n",
      "wrote row 130\n",
      "wrote row 131\n",
      "wrote row 132\n",
      "wrote row 133\n",
      "wrote row 134\n",
      "wrote row 135\n",
      "wrote row 136\n",
      "wrote row 137\n",
      "wrote row 138\n",
      "wrote row 139\n",
      "wrote row 140\n",
      "wrote row 141\n",
      "wrote row 142\n",
      "wrote row 143\n",
      "wrote row 144\n",
      "wrote row 145\n",
      "wrote row 146\n",
      "wrote row 147\n",
      "wrote row 148\n",
      "wrote row 149\n",
      "wrote row 150\n",
      "wrote row 151\n",
      "wrote row 152\n",
      "wrote row 153\n",
      "wrote row 154\n",
      "wrote row 155\n",
      "wrote row 156\n",
      "wrote row 157\n",
      "wrote row 158\n",
      "wrote row 159\n",
      "wrote row 160\n",
      "wrote row 161\n",
      "wrote row 162\n",
      "wrote row 163\n",
      "wrote row 164\n",
      "wrote row 165\n",
      "wrote row 166\n",
      "wrote row 167\n",
      "wrote row 168\n",
      "wrote row 169\n",
      "wrote row 170\n",
      "wrote row 171\n",
      "wrote row 172\n",
      "wrote row 173\n",
      "wrote row 174\n",
      "wrote row 175\n",
      "wrote row 176\n",
      "wrote row 177\n",
      "wrote row 178\n",
      "wrote row 179\n",
      "wrote row 180\n",
      "wrote row 181\n",
      "wrote row 182\n",
      "wrote row 183\n",
      "wrote row 184\n",
      "wrote row 185\n",
      "wrote row 186\n",
      "wrote row 187\n",
      "wrote row 188\n",
      "wrote row 189\n",
      "wrote row 190\n",
      "wrote row 191\n",
      "wrote row 192\n",
      "wrote row 193\n",
      "wrote row 194\n",
      "wrote row 195\n",
      "wrote row 196\n",
      "wrote row 197\n",
      "wrote row 198\n",
      "wrote row 199\n",
      "wrote row 200\n",
      "wrote row 201\n",
      "wrote row 202\n",
      "wrote row 203\n",
      "wrote row 204\n",
      "wrote row 205\n",
      "wrote row 206\n",
      "wrote row 207\n",
      "wrote row 208\n",
      "wrote row 209\n",
      "wrote row 210\n",
      "wrote row 211\n",
      "wrote row 212\n",
      "wrote row 213\n",
      "wrote row 214\n",
      "wrote row 215\n",
      "wrote row 216\n",
      "wrote row 217\n",
      "wrote row 218\n",
      "wrote row 219\n",
      "wrote row 220\n",
      "wrote row 221\n",
      "wrote row 222\n",
      "wrote row 223\n",
      "wrote row 224\n",
      "wrote row 225\n",
      "wrote row 226\n",
      "wrote row 227\n",
      "wrote row 228\n",
      "wrote row 229\n",
      "wrote row 230\n",
      "wrote row 231\n",
      "wrote row 232\n",
      "wrote row 233\n",
      "wrote row 234\n",
      "wrote row 235\n",
      "wrote row 236\n",
      "wrote row 237\n",
      "wrote row 238\n",
      "wrote row 239\n",
      "wrote row 240\n",
      "wrote row 241\n",
      "wrote row 242\n",
      "wrote row 243\n",
      "wrote row 244\n",
      "wrote row 245\n",
      "wrote row 246\n",
      "wrote row 247\n",
      "wrote row 248\n",
      "wrote row 249\n",
      "wrote row 250\n",
      "wrote row 251\n",
      "wrote row 252\n",
      "wrote row 253\n",
      "wrote row 254\n",
      "wrote row 255\n",
      "wrote row 256\n",
      "wrote row 257\n",
      "wrote row 258\n",
      "wrote row 259\n",
      "wrote row 260\n",
      "wrote row 261\n",
      "wrote row 262\n",
      "wrote row 263\n",
      "wrote row 264\n",
      "wrote row 265\n",
      "wrote row 266\n",
      "wrote row 267\n",
      "wrote row 268\n",
      "wrote row 269\n",
      "wrote row 270\n",
      "wrote row 271\n",
      "wrote row 272\n",
      "wrote row 273\n",
      "wrote row 274\n",
      "wrote row 275\n",
      "wrote row 276\n",
      "wrote row 277\n"
     ]
    }
   ],
   "source": [
    "# NB: efficiency could be improved here with groupby and a lambda function, but the data is small enough it shouldn't matter too much\n",
    "\n",
    "# find closest predicate for each response \n",
    "for index, row in responses_df.iterrows():\n",
    "    # lowercase, strip periods and extra whitespace\n",
    "    pred = row['Predicate'].lower().replace(\".\", '').strip()\n",
    "    # get all correct predicates for this sentence\n",
    "    responses = responses_df[responses_df['Full Text'] == row['Full Text']]['ChatGPT response'].unique().tolist()\n",
    "    # lowercase, strip periods and extra whitespace\n",
    "    for r in responses:\n",
    "        r = r.lower().replace(\".\", '').strip()\n",
    "    \n",
    "    # ChatGPT response that best matches this predicate\n",
    "    best_response = ''\n",
    "    exact = 0\n",
    "    # check exact matches\n",
    "    if pred in responses:\n",
    "        exact = 1\n",
    "    \n",
    "    # calculate SBERT cosine similarity \n",
    "    pred_embed = embed_model.encode([pred])\n",
    "    resp_embed = embed_model.encode(responses)\n",
    "    \n",
    "    cosine_scores = util.cos_sim(pred_embed, resp_embed)\n",
    "    # get max cosine score and its index\n",
    "    best_index = torch.argmax(cosine_scores)\n",
    "    best_response = responses[best_index]\n",
    "    best_score = cosine_scores[0][best_index].item()\n",
    "    \n",
    "    # calculate SBERT cosine similarity for dummy sentence\n",
    "    sent_pred = \"All LGBTQ people are \" + pred\n",
    "    sent_responses = [\"All LGBTQ people are \" + r for r in responses]\n",
    "    sp_embed = embed_model.encode([sent_pred])\n",
    "    sr_embed = embed_model.encode(sent_responses)\n",
    "    \n",
    "    s_cosine_scores = util.cos_sim(sp_embed, sr_embed)\n",
    "    # get max cosine score and its index\n",
    "    s_best_index = torch.argmax(cosine_scores)\n",
    "    if s_best_index != best_index:\n",
    "        print(\"difference in best match!\")\n",
    "    s_best_response = responses[s_best_index]\n",
    "    s_best_score = s_cosine_scores[0][s_best_index].item()\n",
    "    \n",
    "    # write row to results_df\n",
    "    results_df.at[index, 'Full Text'] = row['Full Text']\n",
    "    results_df.at[index, 'Predicate'] = row['Predicate']\n",
    "    results_df.at[index, 'ID subgroups'] = row['ID subgroups'] if row.notnull()['ID subgroups'] else \"LGBTQ\"\n",
    "    results_df.at[index, 'Best response'] = best_response\n",
    "    results_df.at[index, 'Exact Match'] = exact\n",
    "    results_df.at[index, 'Phrase Cosine Sim.'] = best_score\n",
    "    results_df.at[index, 'Sent. Cosine Sim.'] = s_best_score\n",
    "    results_df.at[index, 'Extraction Outcome'] = row['Extraction Outcome']\n",
    "    \n",
    "    print(\"wrote row\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ed526605",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>ID subgroups</th>\n",
       "      <th>Best response</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>Phrase Cosine Sim.</th>\n",
       "      <th>Sent. Cosine Sim.</th>\n",
       "      <th>Extraction Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>abnormal</td>\n",
       "      <td>LGBTQ</td>\n",
       "      <td>are abnormal</td>\n",
       "      <td>0</td>\n",
       "      <td>0.82795</td>\n",
       "      <td>0.989485</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>crazy</td>\n",
       "      <td>LGBTQ</td>\n",
       "      <td>are crazy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.647407</td>\n",
       "      <td>0.987745</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>have family issues</td>\n",
       "      <td>LGBTQ</td>\n",
       "      <td>have family issues</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LGBTQ+ people are abnormal, crazy, have family...</td>\n",
       "      <td>have health issues</td>\n",
       "      <td>LGBTQ</td>\n",
       "      <td>have health issues</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Unfit for professional work</td>\n",
       "      <td>unfit for professional work</td>\n",
       "      <td>LGBTQ</td>\n",
       "      <td>struggle with mental health</td>\n",
       "      <td>0</td>\n",
       "      <td>0.237125</td>\n",
       "      <td>0.575729</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>273</th>\n",
       "      <td>slurs/ being treated like there's something wr...</td>\n",
       "      <td>there is something wrong</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>All pansexual people are abnormal.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.284982</td>\n",
       "      <td>0.708158</td>\n",
       "      <td>grammar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>274</th>\n",
       "      <td>Being undermined in an academic environment</td>\n",
       "      <td>undermined in an academic environment</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>All pansexual people struggle.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.097492</td>\n",
       "      <td>0.548966</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>275</th>\n",
       "      <td>More willing to have threesomes, \"easy\", bigge...</td>\n",
       "      <td>more willing to have threesomes</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>More likely to engage in threesomes.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.792879</td>\n",
       "      <td>0.947729</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>More willing to have threesomes, \"easy\", bigge...</td>\n",
       "      <td>easy</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>cheat on their partners</td>\n",
       "      <td>0</td>\n",
       "      <td>0.228233</td>\n",
       "      <td>0.518241</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>277</th>\n",
       "      <td>More willing to have threesomes, \"easy\", bigge...</td>\n",
       "      <td>bigger chance of cheating</td>\n",
       "      <td>Pansexual</td>\n",
       "      <td>More likely to engage in threesomes.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.551818</td>\n",
       "      <td>0.754828</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>278 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Full Text  \\\n",
       "0    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "1    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "2    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "3    LGBTQ+ people are abnormal, crazy, have family...   \n",
       "4                          Unfit for professional work   \n",
       "..                                                 ...   \n",
       "273  slurs/ being treated like there's something wr...   \n",
       "274        Being undermined in an academic environment   \n",
       "275  More willing to have threesomes, \"easy\", bigge...   \n",
       "276  More willing to have threesomes, \"easy\", bigge...   \n",
       "277  More willing to have threesomes, \"easy\", bigge...   \n",
       "\n",
       "                                 Predicate ID subgroups  \\\n",
       "0                                 abnormal        LGBTQ   \n",
       "1                                    crazy        LGBTQ   \n",
       "2                       have family issues        LGBTQ   \n",
       "3                       have health issues        LGBTQ   \n",
       "4              unfit for professional work        LGBTQ   \n",
       "..                                     ...          ...   \n",
       "273              there is something wrong     Pansexual   \n",
       "274  undermined in an academic environment    Pansexual   \n",
       "275        more willing to have threesomes    Pansexual   \n",
       "276                                   easy    Pansexual   \n",
       "277             bigger chance of cheating     Pansexual   \n",
       "\n",
       "                            Best response Exact Match Phrase Cosine Sim.  \\\n",
       "0                            are abnormal           0            0.82795   \n",
       "1                               are crazy           0           0.647407   \n",
       "2                      have family issues           1                1.0   \n",
       "3                      have health issues           1                1.0   \n",
       "4             struggle with mental health           0           0.237125   \n",
       "..                                    ...         ...                ...   \n",
       "273    All pansexual people are abnormal.           0           0.284982   \n",
       "274        All pansexual people struggle.           0           0.097492   \n",
       "275  More likely to engage in threesomes.           0           0.792879   \n",
       "276               cheat on their partners           0           0.228233   \n",
       "277  More likely to engage in threesomes.           0           0.551818   \n",
       "\n",
       "    Sent. Cosine Sim. Extraction Outcome  \n",
       "0            0.989485            correct  \n",
       "1            0.987745            correct  \n",
       "2                 1.0            correct  \n",
       "3                 1.0            correct  \n",
       "4            0.575729      hallucination  \n",
       "..                ...                ...  \n",
       "273          0.708158            grammar  \n",
       "274          0.548966      hallucination  \n",
       "275          0.947729      hallucination  \n",
       "276          0.518241            correct  \n",
       "277          0.754828            correct  \n",
       "\n",
       "[278 rows x 8 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c7ff738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID subgroups\n",
       "Asexual        0.397418\n",
       "Bisexual       0.428189\n",
       "Gay            0.520412\n",
       "LGBTQ            0.5372\n",
       "Lesbian        0.416833\n",
       "Nonbinary      0.512742\n",
       "Pansexual      0.393002\n",
       "Queer          0.466635\n",
       "Transgender     0.44074\n",
       "Name: Phrase Cosine Sim., dtype: object"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby([\"ID subgroups\"])['Phrase Cosine Sim.'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e5328173",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4688638756118661"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Phrase Cosine Sim.'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "61595374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID subgroups\n",
       "Asexual        0.740199\n",
       "Bisexual       0.755286\n",
       "Gay            0.825764\n",
       "LGBTQ          0.835171\n",
       "Lesbian        0.744472\n",
       "Nonbinary      0.819037\n",
       "Pansexual      0.706633\n",
       "Queer          0.786981\n",
       "Transgender    0.749971\n",
       "Name: Sent. Cosine Sim., dtype: object"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby([\"ID subgroups\"])['Sent. Cosine Sim.'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "957f3f88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7836801141714879"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Sent. Cosine Sim.'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "c8831fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID subgroups  Exact Match\n",
       "Asexual       0              24\n",
       "Bisexual      0              40\n",
       "              1               2\n",
       "Gay           0              53\n",
       "              1               3\n",
       "LGBTQ         0              33\n",
       "              1               3\n",
       "Lesbian       0              16\n",
       "              1               1\n",
       "Nonbinary     0              24\n",
       "              1               3\n",
       "Pansexual     0              17\n",
       "Queer         0              26\n",
       "              1               2\n",
       "Transgender   0              30\n",
       "              1               1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby([\"ID subgroups\"])['Exact Match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "659464ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exact Match\n",
       "0    263\n",
       "1     15\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Exact Match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a55a0b2b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ID subgroups  Extraction Outcome\n",
       "Asexual       grammar               0.500000\n",
       "              hallucination         0.250000\n",
       "              correct               0.125000\n",
       "              opposite              0.083333\n",
       "              other                 0.041667\n",
       "Bisexual      hallucination         0.428571\n",
       "              correct               0.309524\n",
       "              grammar               0.214286\n",
       "              other                 0.023810\n",
       "              opposite              0.023810\n",
       "Gay           correct               0.571429\n",
       "              hallucination         0.196429\n",
       "              grammar               0.196429\n",
       "              other                 0.017857\n",
       "              opposite              0.017857\n",
       "LGBTQ         correct               0.527778\n",
       "              hallucination         0.305556\n",
       "              opposite              0.083333\n",
       "              other                 0.055556\n",
       "              grammar               0.027778\n",
       "Lesbian       correct               0.352941\n",
       "              opposite              0.294118\n",
       "              grammar               0.176471\n",
       "              hallucination         0.117647\n",
       "              other                 0.058824\n",
       "Nonbinary     hallucination         0.481481\n",
       "              correct               0.333333\n",
       "              grammar               0.148148\n",
       "              opposite              0.037037\n",
       "Pansexual     hallucination         0.411765\n",
       "              grammar               0.352941\n",
       "              correct               0.176471\n",
       "              other                 0.058824\n",
       "Queer         correct               0.357143\n",
       "              hallucination         0.321429\n",
       "              grammar               0.250000\n",
       "              opposite              0.071429\n",
       "Transgender   correct               0.354839\n",
       "              hallucination         0.322581\n",
       "              grammar               0.225806\n",
       "              opposite              0.064516\n",
       "              other                 0.032258\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df.groupby([\"ID subgroups\"])['Extraction Outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "56e6ebe0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extraction Outcome\n",
       "correct          0.381295\n",
       "hallucination    0.312950\n",
       "grammar          0.215827\n",
       "opposite         0.061151\n",
       "other            0.028777\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Extraction Outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "9508a4e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>ID subgroups</th>\n",
       "      <th>Best response</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>Phrase Cosine Sim.</th>\n",
       "      <th>Sent. Cosine Sim.</th>\n",
       "      <th>Extraction Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>Easily fall in love with straight guys and hav...</td>\n",
       "      <td>Easily fall in love with straight guys and hav...</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are promiscuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0.436906</td>\n",
       "      <td>0.644943</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>Homophobia, monkeypox, hiv. Dirty</td>\n",
       "      <td>have monkeypox</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are diseased</td>\n",
       "      <td>0</td>\n",
       "      <td>0.337342</td>\n",
       "      <td>0.669088</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>There's the stigma that the gay community is \"...</td>\n",
       "      <td>pedophile</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are promiscuous.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.367087</td>\n",
       "      <td>0.693452</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>108</th>\n",
       "      <td>There's the stigma that the gay community is \"...</td>\n",
       "      <td>groomer</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are flamboyant.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.141368</td>\n",
       "      <td>0.605898</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>I think the big one that I usually hear is des...</td>\n",
       "      <td>bad</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are promiscuous.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.15583</td>\n",
       "      <td>0.579438</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>(1) hypersexual (2) love hard drugs (3) just p...</td>\n",
       "      <td>not serious about career</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are carefree</td>\n",
       "      <td>0</td>\n",
       "      <td>0.127956</td>\n",
       "      <td>0.592248</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>116</th>\n",
       "      <td>Not \"normal\", must be effeminate</td>\n",
       "      <td>not normal</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are promiscuous</td>\n",
       "      <td>0</td>\n",
       "      <td>0.167817</td>\n",
       "      <td>0.600583</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>Religious sinful mentalities</td>\n",
       "      <td>sinful</td>\n",
       "      <td>Gay</td>\n",
       "      <td>All gay people engage in promiscuous behavior.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.263079</td>\n",
       "      <td>0.656176</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>130</th>\n",
       "      <td>Both that we're post-sexual as well as creepy ...</td>\n",
       "      <td>post-sexual</td>\n",
       "      <td>Gay</td>\n",
       "      <td>All queer people are post-sexual.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.646741</td>\n",
       "      <td>0.945093</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>131</th>\n",
       "      <td>Both that we're post-sexual as well as creepy ...</td>\n",
       "      <td>creepy</td>\n",
       "      <td>Gay</td>\n",
       "      <td>All queer people are creepy.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.510929</td>\n",
       "      <td>0.938331</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>I'm not a real man and less masculine because ...</td>\n",
       "      <td>not a real man</td>\n",
       "      <td>Gay</td>\n",
       "      <td>are effeminate</td>\n",
       "      <td>0</td>\n",
       "      <td>0.234319</td>\n",
       "      <td>0.680292</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Full Text  \\\n",
       "96   Easily fall in love with straight guys and hav...   \n",
       "100                  Homophobia, monkeypox, hiv. Dirty   \n",
       "107  There's the stigma that the gay community is \"...   \n",
       "108  There's the stigma that the gay community is \"...   \n",
       "109  I think the big one that I usually hear is des...   \n",
       "114  (1) hypersexual (2) love hard drugs (3) just p...   \n",
       "116                   Not \"normal\", must be effeminate   \n",
       "121                      Religious sinful mentalities    \n",
       "130  Both that we're post-sexual as well as creepy ...   \n",
       "131  Both that we're post-sexual as well as creepy ...   \n",
       "132  I'm not a real man and less masculine because ...   \n",
       "\n",
       "                                             Predicate ID subgroups  \\\n",
       "96   Easily fall in love with straight guys and hav...          Gay   \n",
       "100                                     have monkeypox          Gay   \n",
       "107                                          pedophile          Gay   \n",
       "108                                            groomer          Gay   \n",
       "109                                                bad          Gay   \n",
       "114                           not serious about career          Gay   \n",
       "116                                         not normal          Gay   \n",
       "121                                             sinful          Gay   \n",
       "130                                        post-sexual          Gay   \n",
       "131                                             creepy          Gay   \n",
       "132                                     not a real man          Gay   \n",
       "\n",
       "                                      Best response Exact Match  \\\n",
       "96                                  are promiscuous           0   \n",
       "100                                    are diseased           0   \n",
       "107                                are promiscuous.           0   \n",
       "108                                 are flamboyant.           0   \n",
       "109                                are promiscuous.           0   \n",
       "114                                    are carefree           0   \n",
       "116                                 are promiscuous           0   \n",
       "121  All gay people engage in promiscuous behavior.           0   \n",
       "130               All queer people are post-sexual.           0   \n",
       "131                    All queer people are creepy.           0   \n",
       "132                                  are effeminate           0   \n",
       "\n",
       "    Phrase Cosine Sim. Sent. Cosine Sim. Extraction Outcome  \n",
       "96            0.436906          0.644943      hallucination  \n",
       "100           0.337342          0.669088      hallucination  \n",
       "107           0.367087          0.693452      hallucination  \n",
       "108           0.141368          0.605898      hallucination  \n",
       "109            0.15583          0.579438      hallucination  \n",
       "114           0.127956          0.592248      hallucination  \n",
       "116           0.167817          0.600583      hallucination  \n",
       "121           0.263079          0.656176      hallucination  \n",
       "130           0.646741          0.945093      hallucination  \n",
       "131           0.510929          0.938331      hallucination  \n",
       "132           0.234319          0.680292      hallucination  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df[(results_df['Extraction Outcome'] == 'hallucination') & (results_df['ID subgroups'] == 'Gay')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35a1e9b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1084cb30",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
