{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e3a6e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92c3ef9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sentence-transformers in /opt/homebrew/lib/python3.11/site-packages (2.2.2)\n",
      "Requirement already satisfied: transformers<5.0.0,>=4.6.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.35.2)\n",
      "Requirement already satisfied: tqdm in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (4.65.0)\n",
      "Requirement already satisfied: torch>=1.6.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (2.1.2)\n",
      "Requirement already satisfied: torchvision in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.16.2)\n",
      "Requirement already satisfied: numpy in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.26.1)\n",
      "Requirement already satisfied: scikit-learn in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: scipy in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (1.11.4)\n",
      "Requirement already satisfied: nltk in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (3.8.1)\n",
      "Requirement already satisfied: sentencepiece in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.1.99)\n",
      "Requirement already satisfied: huggingface-hub>=0.4.0 in /opt/homebrew/lib/python3.11/site-packages (from sentence-transformers) (0.19.4)\n",
      "Requirement already satisfied: filelock in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (3.13.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2023.12.1)\n",
      "Requirement already satisfied: requests in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (2.31.0)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (6.0.1)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (4.7.1)\n",
      "Requirement already satisfied: packaging>=20.9 in /opt/homebrew/lib/python3.11/site-packages (from huggingface-hub>=0.4.0->sentence-transformers) (23.2)\n",
      "Requirement already satisfied: sympy in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\n",
      "Requirement already satisfied: networkx in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /opt/homebrew/lib/python3.11/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (2023.10.3)\n",
      "Requirement already satisfied: tokenizers<0.19,>=0.14 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.15.0)\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/homebrew/lib/python3.11/site-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers) (0.4.1)\n",
      "Requirement already satisfied: click in /opt/homebrew/lib/python3.11/site-packages (from nltk->sentence-transformers) (8.1.7)\n",
      "Requirement already satisfied: joblib in /opt/homebrew/lib/python3.11/site-packages (from nltk->sentence-transformers) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/homebrew/lib/python3.11/site-packages (from scikit-learn->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/homebrew/lib/python3.11/site-packages (from torchvision->sentence-transformers) (10.2.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /opt/homebrew/lib/python3.11/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.2.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/homebrew/lib/python3.11/site-packages (from requests->huggingface-hub>=0.4.0->sentence-transformers) (2023.7.22)\n",
      "Requirement already satisfied: mpmath>=0.19 in /opt/homebrew/lib/python3.11/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.0\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpython3.11 -m pip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip3 install sentence-transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fcc7c1db",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9a1c7848",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Relevant Phrase</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>ID subgroups</th>\n",
       "      <th>Annotator</th>\n",
       "      <th>ChatGPT response</th>\n",
       "      <th>Response outcome</th>\n",
       "      <th>prompt</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "      <th>Unnamed: 8</th>\n",
       "      <th>Unnamed: 9</th>\n",
       "      <th>Unnamed: 10</th>\n",
       "      <th>Unnamed: 11</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jews are late</td>\n",
       "      <td>are late</td>\n",
       "      <td>are late</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>are punctual</td>\n",
       "      <td>opposite</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I don't know much about Jews except that you'...</td>\n",
       "      <td>are good with money</td>\n",
       "      <td>are good with money</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>are good with money</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>I would describe myself as...</td>\n",
       "      <td>Reform-thinking, Conservative-practicing</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jews expect special treatment as a minority gr...</td>\n",
       "      <td>expect special treatment</td>\n",
       "      <td>expect special treatment</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>expect special treatment</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Prefer not to say</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just Jewish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dont go to church, whats it like-beung Jewish/...</td>\n",
       "      <td>don't go to church</td>\n",
       "      <td>don't go to church</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>kill Jesus</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reconstructionist,Renewal,Havurah,Culturally J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dont go to church, whats it like-beung Jewish/...</td>\n",
       "      <td>different</td>\n",
       "      <td>are different</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>worship differently</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reconstructionist,Renewal,Havurah,Culturally J...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>*I have been called an oppressor \\n*I have bee...</td>\n",
       "      <td>called a colonizer</td>\n",
       "      <td>are colonizers</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>are powerful</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>*I have been called an oppressor \\n*I have bee...</td>\n",
       "      <td>called a racist</td>\n",
       "      <td>are racist</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>are manipulative</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reform</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Anything surrounding Israel\\nJewish people are...</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>correct</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative,Just Jewish,Culturally Jewish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>people made fun of me because I was the smart ...</td>\n",
       "      <td>was the smart kid</td>\n",
       "      <td>are smart</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>All Jews were blamed.</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Conservative</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Verbally and physically threatened in Copenhag...</td>\n",
       "      <td>for being a \"shylock\"</td>\n",
       "      <td>are shylocks</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Jon</td>\n",
       "      <td>exploit others for financial gain.</td>\n",
       "      <td>hallucination</td>\n",
       "      <td>From the following sentence, extract a stateme...</td>\n",
       "      <td>Ashkenazi</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Reform,Culturally Jewish</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>211 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Full Text  \\\n",
       "0                                        Jews are late   \n",
       "1    \"I don't know much about Jews except that you'...   \n",
       "2    Jews expect special treatment as a minority gr...   \n",
       "3    Dont go to church, whats it like-beung Jewish/...   \n",
       "4    Dont go to church, whats it like-beung Jewish/...   \n",
       "..                                                 ...   \n",
       "206  *I have been called an oppressor \\n*I have bee...   \n",
       "207  *I have been called an oppressor \\n*I have bee...   \n",
       "208  Anything surrounding Israel\\nJewish people are...   \n",
       "209  people made fun of me because I was the smart ...   \n",
       "210  Verbally and physically threatened in Copenhag...   \n",
       "\n",
       "              Relevant Phrase                 Predicate ID subgroups  \\\n",
       "0                    are late                  are late          NaN   \n",
       "1         are good with money       are good with money          NaN   \n",
       "2    expect special treatment  expect special treatment          NaN   \n",
       "3          don't go to church        don't go to church          NaN   \n",
       "4                   different             are different          NaN   \n",
       "..                        ...                       ...          ...   \n",
       "206        called a colonizer            are colonizers          NaN   \n",
       "207           called a racist                are racist          NaN   \n",
       "208                are greedy                are greedy          NaN   \n",
       "209         was the smart kid                 are smart          NaN   \n",
       "210     for being a \"shylock\"              are shylocks          NaN   \n",
       "\n",
       "    Annotator                    ChatGPT response Response outcome  \\\n",
       "0         Jon                        are punctual         opposite   \n",
       "1         Jon                 are good with money          correct   \n",
       "2         Jon            expect special treatment          correct   \n",
       "3         Jon                          kill Jesus          correct   \n",
       "4         Jon                 worship differently          correct   \n",
       "..        ...                                 ...              ...   \n",
       "206       Jon                        are powerful    hallucination   \n",
       "207       Jon                    are manipulative    hallucination   \n",
       "208       Jon                          are greedy          correct   \n",
       "209       Jon               All Jews were blamed.    hallucination   \n",
       "210       Jon  exploit others for financial gain.    hallucination   \n",
       "\n",
       "                                                prompt         Unnamed: 7  \\\n",
       "0    From the following sentence, extract a stateme...          Ashkenazi   \n",
       "1    From the following sentence, extract a stateme...          Ashkenazi   \n",
       "2    From the following sentence, extract a stateme...  Prefer not to say   \n",
       "3    From the following sentence, extract a stateme...          Ashkenazi   \n",
       "4    From the following sentence, extract a stateme...          Ashkenazi   \n",
       "..                                                 ...                ...   \n",
       "206  From the following sentence, extract a stateme...          Ashkenazi   \n",
       "207  From the following sentence, extract a stateme...          Ashkenazi   \n",
       "208  From the following sentence, extract a stateme...          Ashkenazi   \n",
       "209  From the following sentence, extract a stateme...          Ashkenazi   \n",
       "210  From the following sentence, extract a stateme...          Ashkenazi   \n",
       "\n",
       "    Unnamed: 8                                         Unnamed: 9  \\\n",
       "0          NaN                                       Conservative   \n",
       "1          NaN                      I would describe myself as...   \n",
       "2          NaN                                        Just Jewish   \n",
       "3          NaN  Reconstructionist,Renewal,Havurah,Culturally J...   \n",
       "4          NaN  Reconstructionist,Renewal,Havurah,Culturally J...   \n",
       "..         ...                                                ...   \n",
       "206        NaN                                             Reform   \n",
       "207        NaN                                             Reform   \n",
       "208        NaN         Conservative,Just Jewish,Culturally Jewish   \n",
       "209        NaN                                       Conservative   \n",
       "210        NaN                           Reform,Culturally Jewish   \n",
       "\n",
       "                                  Unnamed: 10 Unnamed: 11  \n",
       "0                                         NaN         NaN  \n",
       "1    Reform-thinking, Conservative-practicing         NaN  \n",
       "2                                         NaN         NaN  \n",
       "3                                         NaN         NaN  \n",
       "4                                         NaN         NaN  \n",
       "..                                        ...         ...  \n",
       "206                                       NaN         NaN  \n",
       "207                                       NaN         NaN  \n",
       "208                                       NaN         NaN  \n",
       "209                                       NaN         NaN  \n",
       "210                                       NaN         NaN  \n",
       "\n",
       "[211 rows x 13 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load responses\n",
    "responses_df = pd.read_csv('./GPT responses.csv')\n",
    "responses_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e8310d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(columns=['Full Text', 'Predicate', 'ID subgroups', 'Best response', 'Exact Match', 'Phrase Cosine Sim.', 'Sent. Cosine Sim.', 'Extraction Outcome'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "ecfa8b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f5f4c3da",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote row 0\n",
      "wrote row 1\n",
      "wrote row 2\n",
      "wrote row 3\n",
      "wrote row 4\n",
      "wrote row 5\n",
      "wrote row 6\n",
      "wrote row 7\n",
      "wrote row 8\n",
      "wrote row 9\n",
      "wrote row 10\n",
      "wrote row 11\n",
      "wrote row 12\n",
      "wrote row 13\n",
      "wrote row 14\n",
      "wrote row 15\n",
      "wrote row 16\n",
      "wrote row 17\n",
      "wrote row 18\n",
      "wrote row 19\n",
      "wrote row 20\n",
      "wrote row 21\n",
      "wrote row 22\n",
      "wrote row 23\n",
      "wrote row 24\n",
      "wrote row 25\n",
      "wrote row 26\n",
      "wrote row 27\n",
      "wrote row 28\n",
      "wrote row 29\n",
      "wrote row 30\n",
      "wrote row 31\n",
      "wrote row 32\n",
      "wrote row 33\n",
      "wrote row 34\n",
      "wrote row 35\n",
      "wrote row 36\n",
      "wrote row 37\n",
      "wrote row 38\n",
      "wrote row 39\n",
      "wrote row 40\n",
      "wrote row 41\n",
      "wrote row 42\n",
      "wrote row 43\n",
      "wrote row 44\n",
      "wrote row 45\n",
      "wrote row 46\n",
      "wrote row 47\n",
      "wrote row 48\n",
      "wrote row 49\n",
      "wrote row 50\n",
      "wrote row 51\n",
      "wrote row 52\n",
      "wrote row 53\n",
      "wrote row 54\n",
      "wrote row 55\n",
      "wrote row 56\n",
      "wrote row 57\n",
      "wrote row 58\n",
      "wrote row 59\n",
      "wrote row 60\n",
      "wrote row 61\n",
      "wrote row 62\n",
      "wrote row 63\n",
      "wrote row 64\n",
      "wrote row 65\n",
      "wrote row 66\n",
      "wrote row 67\n",
      "wrote row 68\n",
      "wrote row 69\n",
      "wrote row 70\n",
      "wrote row 71\n",
      "wrote row 72\n",
      "wrote row 73\n",
      "wrote row 74\n",
      "wrote row 75\n",
      "wrote row 76\n",
      "wrote row 77\n",
      "wrote row 78\n",
      "wrote row 79\n",
      "wrote row 80\n",
      "wrote row 81\n",
      "wrote row 82\n",
      "wrote row 83\n",
      "wrote row 84\n",
      "wrote row 85\n",
      "wrote row 86\n",
      "wrote row 87\n",
      "null pred\n",
      "wrote row 89\n",
      "wrote row 90\n",
      "wrote row 91\n",
      "wrote row 92\n",
      "wrote row 93\n",
      "wrote row 94\n",
      "wrote row 95\n",
      "wrote row 96\n",
      "wrote row 97\n",
      "wrote row 98\n",
      "wrote row 99\n",
      "wrote row 100\n",
      "wrote row 101\n",
      "wrote row 102\n",
      "wrote row 103\n",
      "wrote row 104\n",
      "wrote row 105\n",
      "wrote row 106\n",
      "wrote row 107\n",
      "wrote row 108\n",
      "wrote row 109\n",
      "wrote row 110\n",
      "wrote row 111\n",
      "wrote row 112\n",
      "wrote row 113\n",
      "wrote row 114\n",
      "wrote row 115\n",
      "wrote row 116\n",
      "wrote row 117\n",
      "wrote row 118\n",
      "wrote row 119\n",
      "wrote row 120\n",
      "wrote row 121\n",
      "wrote row 122\n",
      "wrote row 123\n",
      "wrote row 124\n",
      "wrote row 125\n",
      "wrote row 126\n",
      "wrote row 127\n",
      "wrote row 128\n",
      "wrote row 129\n",
      "wrote row 130\n",
      "wrote row 131\n",
      "wrote row 132\n",
      "wrote row 133\n",
      "wrote row 134\n",
      "wrote row 135\n",
      "wrote row 136\n",
      "wrote row 137\n",
      "wrote row 138\n",
      "wrote row 139\n",
      "wrote row 140\n",
      "wrote row 141\n",
      "wrote row 142\n",
      "wrote row 143\n",
      "wrote row 144\n",
      "wrote row 145\n",
      "wrote row 146\n",
      "wrote row 147\n",
      "wrote row 148\n",
      "wrote row 149\n",
      "wrote row 150\n",
      "null pred\n",
      "wrote row 152\n",
      "wrote row 153\n",
      "wrote row 154\n",
      "wrote row 155\n",
      "wrote row 156\n",
      "wrote row 157\n",
      "wrote row 158\n",
      "wrote row 159\n",
      "wrote row 160\n",
      "wrote row 161\n",
      "wrote row 162\n",
      "wrote row 163\n",
      "wrote row 164\n",
      "wrote row 165\n",
      "wrote row 166\n",
      "wrote row 167\n",
      "wrote row 168\n",
      "wrote row 169\n",
      "wrote row 170\n",
      "wrote row 171\n",
      "wrote row 172\n",
      "wrote row 173\n",
      "wrote row 174\n",
      "null pred\n",
      "wrote row 176\n",
      "wrote row 177\n",
      "wrote row 178\n",
      "wrote row 179\n",
      "wrote row 180\n",
      "wrote row 181\n",
      "wrote row 182\n",
      "wrote row 183\n",
      "wrote row 184\n",
      "wrote row 185\n",
      "wrote row 186\n",
      "wrote row 187\n",
      "wrote row 188\n",
      "null pred\n",
      "null pred\n",
      "wrote row 191\n",
      "wrote row 192\n",
      "wrote row 193\n",
      "null pred\n",
      "null pred\n",
      "wrote row 196\n",
      "wrote row 197\n",
      "wrote row 198\n",
      "wrote row 199\n",
      "wrote row 200\n",
      "wrote row 201\n",
      "wrote row 202\n",
      "wrote row 203\n",
      "wrote row 204\n",
      "wrote row 205\n",
      "wrote row 206\n",
      "wrote row 207\n",
      "wrote row 208\n",
      "wrote row 209\n",
      "wrote row 210\n"
     ]
    }
   ],
   "source": [
    "# NB: efficiency could be improved here with groupby and a lambda function, but the data is small enough it shouldn't matter too much\n",
    "\n",
    "# find closest predicate for each response \n",
    "for index, row in responses_df.iterrows():\n",
    "    # lowercase, strip periods and extra whitespace\n",
    "    if row.isnull()['Predicate']:\n",
    "        print(\"null pred\")\n",
    "        continue\n",
    "    pred = row['Predicate'].lower().replace(\".\", '').strip()\n",
    "    # get all correct predicates for this sentence\n",
    "    responses = responses_df[responses_df['Full Text'] == row['Full Text']]['ChatGPT response'].unique().tolist()\n",
    "    # lowercase, strip periods and extra whitespace\n",
    "    for r in responses:\n",
    "        r = r.lower().replace(\".\", '').strip()\n",
    "    \n",
    "    # ChatGPT response that best matches this predicate\n",
    "    best_response = ''\n",
    "    exact = 0\n",
    "    # check exact matches\n",
    "    if pred in responses:\n",
    "        exact = 1\n",
    "    \n",
    "    # calculate SBERT cosine similarity \n",
    "    pred_embed = embed_model.encode([pred])\n",
    "    resp_embed = embed_model.encode(responses)\n",
    "    \n",
    "    cosine_scores = util.cos_sim(pred_embed, resp_embed)\n",
    "    # get max cosine score and its index\n",
    "    best_index = torch.argmax(cosine_scores)\n",
    "    best_response = responses[best_index]\n",
    "    best_score = cosine_scores[0][best_index].item()\n",
    "    \n",
    "    # calculate SBERT cosine similarity for dummy sentence\n",
    "    sent_pred = \"All Jewish people are \" + pred\n",
    "    sent_responses = [\"All Jewish people are \" + r for r in responses]\n",
    "    sp_embed = embed_model.encode([sent_pred])\n",
    "    sr_embed = embed_model.encode(sent_responses)\n",
    "    \n",
    "    s_cosine_scores = util.cos_sim(sp_embed, sr_embed)\n",
    "    # get max cosine score and its index\n",
    "    s_best_index = torch.argmax(cosine_scores)\n",
    "    if s_best_index != best_index:\n",
    "        print(\"difference in best match!\")\n",
    "    s_best_response = responses[s_best_index]\n",
    "    s_best_score = s_cosine_scores[0][s_best_index].item()\n",
    "    \n",
    "    # write row to results_df\n",
    "    results_df.at[index, 'Full Text'] = row['Full Text']\n",
    "    results_df.at[index, 'Predicate'] = row['Predicate']\n",
    "    results_df.at[index, 'ID subgroups'] = row['ID subgroups'] if row.notnull()['ID subgroups'] else \"Jewish\"\n",
    "    results_df.at[index, 'Best response'] = best_response\n",
    "    results_df.at[index, 'Exact Match'] = exact\n",
    "    results_df.at[index, 'Phrase Cosine Sim.'] = best_score\n",
    "    results_df.at[index, 'Extraction Outcome'] = row['Response outcome']\n",
    "    results_df.at[index, 'Sent. Cosine Sim.'] = s_best_score\n",
    "    \n",
    "    print(\"wrote row\", index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ed526605",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Full Text</th>\n",
       "      <th>Predicate</th>\n",
       "      <th>ID subgroups</th>\n",
       "      <th>Best response</th>\n",
       "      <th>Exact Match</th>\n",
       "      <th>Phrase Cosine Sim.</th>\n",
       "      <th>Sent. Cosine Sim.</th>\n",
       "      <th>Extraction Outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jews are late</td>\n",
       "      <td>are late</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>are punctual</td>\n",
       "      <td>0</td>\n",
       "      <td>0.618577</td>\n",
       "      <td>0.828589</td>\n",
       "      <td>opposite</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>\"I don't know much about Jews except that you'...</td>\n",
       "      <td>are good with money</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>are good with money</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Jews expect special treatment as a minority gr...</td>\n",
       "      <td>expect special treatment</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>expect special treatment</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dont go to church, whats it like-beung Jewish/...</td>\n",
       "      <td>don't go to church</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>kill Jesus</td>\n",
       "      <td>0</td>\n",
       "      <td>0.446777</td>\n",
       "      <td>0.662429</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dont go to church, whats it like-beung Jewish/...</td>\n",
       "      <td>are different</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>believe in different things</td>\n",
       "      <td>0</td>\n",
       "      <td>0.345289</td>\n",
       "      <td>0.813228</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>*I have been called an oppressor \\n*I have bee...</td>\n",
       "      <td>are colonizers</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.275132</td>\n",
       "      <td>0.636283</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>*I have been called an oppressor \\n*I have bee...</td>\n",
       "      <td>are racist</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>0</td>\n",
       "      <td>0.502888</td>\n",
       "      <td>0.676046</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>Anything surrounding Israel\\nJewish people are...</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>are greedy</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>correct</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>people made fun of me because I was the smart ...</td>\n",
       "      <td>are smart</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>All Jews were blamed.</td>\n",
       "      <td>0</td>\n",
       "      <td>0.104006</td>\n",
       "      <td>0.551251</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>Verbally and physically threatened in Copenhag...</td>\n",
       "      <td>are shylocks</td>\n",
       "      <td>Jewish</td>\n",
       "      <td>exploit others for financial gain.</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.006714</td>\n",
       "      <td>0.583402</td>\n",
       "      <td>hallucination</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>204 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Full Text  \\\n",
       "0                                        Jews are late   \n",
       "1    \"I don't know much about Jews except that you'...   \n",
       "2    Jews expect special treatment as a minority gr...   \n",
       "3    Dont go to church, whats it like-beung Jewish/...   \n",
       "4    Dont go to church, whats it like-beung Jewish/...   \n",
       "..                                                 ...   \n",
       "206  *I have been called an oppressor \\n*I have bee...   \n",
       "207  *I have been called an oppressor \\n*I have bee...   \n",
       "208  Anything surrounding Israel\\nJewish people are...   \n",
       "209  people made fun of me because I was the smart ...   \n",
       "210  Verbally and physically threatened in Copenhag...   \n",
       "\n",
       "                    Predicate ID subgroups  \\\n",
       "0                    are late       Jewish   \n",
       "1         are good with money       Jewish   \n",
       "2    expect special treatment       Jewish   \n",
       "3          don't go to church       Jewish   \n",
       "4               are different       Jewish   \n",
       "..                        ...          ...   \n",
       "206            are colonizers       Jewish   \n",
       "207                are racist       Jewish   \n",
       "208                are greedy       Jewish   \n",
       "209                 are smart       Jewish   \n",
       "210              are shylocks       Jewish   \n",
       "\n",
       "                          Best response Exact Match Phrase Cosine Sim.  \\\n",
       "0                          are punctual           0           0.618577   \n",
       "1                   are good with money           1                1.0   \n",
       "2              expect special treatment           1                1.0   \n",
       "3                            kill Jesus           0           0.446777   \n",
       "4           believe in different things           0           0.345289   \n",
       "..                                  ...         ...                ...   \n",
       "206                          are greedy           0           0.275132   \n",
       "207                          are greedy           0           0.502888   \n",
       "208                          are greedy           1                1.0   \n",
       "209               All Jews were blamed.           0           0.104006   \n",
       "210  exploit others for financial gain.           0          -0.006714   \n",
       "\n",
       "    Sent. Cosine Sim. Extraction Outcome  \n",
       "0            0.828589           opposite  \n",
       "1                 1.0            correct  \n",
       "2                 1.0            correct  \n",
       "3            0.662429            correct  \n",
       "4            0.813228            correct  \n",
       "..                ...                ...  \n",
       "206          0.636283      hallucination  \n",
       "207          0.676046      hallucination  \n",
       "208               1.0            correct  \n",
       "209          0.551251      hallucination  \n",
       "210          0.583402      hallucination  \n",
       "\n",
       "[204 rows x 8 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c7ff738f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6092528160661459"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Phrase Cosine Sim.'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "eaa26495",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8175807016737321"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Sent. Cosine Sim.'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "c8831fee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Exact Match\n",
       "0    167\n",
       "1     37\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Exact Match'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "659464ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Extraction Outcome\n",
       "correct          0.455882\n",
       "grammar          0.196078\n",
       "hallucination    0.196078\n",
       "other            0.117647\n",
       "opposite         0.034314\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df['Extraction Outcome'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "388e4395",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = results_df[(results_df['Extraction Outcome'] == 'other') & (results_df['ID subgroups'] == 'Jewish')]['Full Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73a5ee02",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " By anti-Semites  scrubbed and beaten up and called bad names;   other discriminated against us for not  seeking middle class Jewish box and rejecting us from community and services\n",
      "I cannot recall ever experiencing an antisemitic slur directed at me particularly. I have had antisemitic slurs directed at groups I was part of by onlookers (i.e. during March of the Living having someone yell at our group). I have also experienced people making generalized slurs against the Jewish people in front of me not realizing I was Jewish. Lastly, I have experienced antisemitic graffiti (swastikas) in public places that were not directed at me but still felt harmful.\n",
      "Yes. That we lie about needing extra/different days off to observe Jewish holidays\n",
      "Jewish people are more loyal to Israel than their home countries.\n",
      "Jews love money: When I was a child teenagers on the top deck of a London bus threw small change down at me and my father. It was very confusing and I didn't understand why I was told to keep walking and not look up. Years later I understood. \n",
      "Jews love money: When I was a child teenagers on the top deck of a London bus threw small change down at me and my father. It was very confusing and I didn't understand why I was told to keep walking and not look up. Years later I understood. \n",
      "Jewish people consider themselves superior to others.\n",
      "Jews control the US government/Jews control US foreign policy\n",
      "\n",
      "Jews are smart (independent of grades)\n",
      "\n",
      "Jews are good with money (accounting, budgeting)\n",
      "\n",
      "Jews are overly focused on details and language in the Bible and aren't as focused on morals\n",
      "Jews control the US government/Jews control US foreign policy\n",
      "\n",
      "Jews are smart (independent of grades)\n",
      "\n",
      "Jews are good with money (accounting, budgeting)\n",
      "\n",
      "Jews are overly focused on details and language in the Bible and aren't as focused on morals\n",
      "Jews control the US government/Jews control US foreign policy\n",
      "\n",
      "Jews are smart (independent of grades)\n",
      "\n",
      "Jews are good with money (accounting, budgeting)\n",
      "\n",
      "Jews are overly focused on details and language in the Bible and aren't as focused on morals\n",
      "Jews control the US government/Jews control US foreign policy\n",
      "\n",
      "Jews are smart (independent of grades)\n",
      "\n",
      "Jews are good with money (accounting, budgeting)\n",
      "\n",
      "Jews are overly focused on details and language in the Bible and aren't as focused on morals\n",
      "Jews control the US government/Jews control US foreign policy\n",
      "\n",
      "Jews are smart (independent of grades)\n",
      "\n",
      "Jews are good with money (accounting, budgeting)\n",
      "\n",
      "Jews are overly focused on details and language in the Bible and aren't as focused on morals\n",
      "Jews control the US government/Jews control US foreign policy\n",
      "\n",
      "Jews are smart (independent of grades)\n",
      "\n",
      "Jews are good with money (accounting, budgeting)\n",
      "\n",
      "Jews are overly focused on details and language in the Bible and aren't as focused on morals\n",
      "That I would be either a lawyer or doctor\n",
      "Nepotism, implying Jewish people are more likely to take care of their own \n",
      "Using religion to exempt myself from “regular” activities (school, medical requirements, etc)\n",
      "call Anthony, Diana, experience, antisemitic, slurs, and outright discrimination, where we were told that we could not going to clubs and other facilities.\n",
      "I’ve had pennies thrown at me. The day after Trump’s election in 2016, I was walking my child to school (he was 8 and wearing a kippah) and a stranger came up to us and yelled “TRUMP!” in our faces. I don’t know if that was meant to be anti-Semitic or not but it felt like it at the time. I’ve heard “New York” used to mean “Jewish” a lot by people who also call people like me “pushy.” In person I don’t see much overt stereotyping- it’s all subtler.\n",
      "Converged upon by a small group in elementary school:  \"You're so lucky that you get to take school off [for Rosh Hashanah and Yom Kippur]. I want days off [to presumably do nothing].\"\n",
      "\n",
      "College acquaintance while with me in the college bookstore:\n",
      "You looking for something specific?\n",
      "ME: No, just wandering around\n",
      "HER: Well, you Jews ARE Wanderers.\n",
      "\n",
      "Chased around the playground at 9: \"When you die, Jesus is going to come and paint sixes on your head and you are going to hell because you don't believe in him.\"\n",
      "\n",
      "\"Are you going to change your name to _____berg?\" [asked of my husband by his mother when he was converting to Judaism].\n",
      "\n",
      "\"I've seen _Fiddler on the Roof_!\"\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for t in text:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12bc1833",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
